import asyncio
import copy
import logging
from collections import deque
from typing import Annotated, List

from livekit import agents, rtc
from livekit.agents import JobContext, JobRequest, WorkerOptions, cli, tokenize, tts
from livekit.agents.llm import (
    ChatContext,
    ChatMessage,
    ChatRole,
)
from livekit.agents.voice_assistant import AssistantContext, VoiceAssistant
from livekit.plugins import deepgram, openai, silero#, elebenlabs
from dotenv import load_dotenv
import os
import logging
from logging_config import setup_logging

load_dotenv()

MAX_IMAGES = 3
NO_IMAGE_MESSAGE_GENERIC = (
    "Lo siento, no tengo una imagen para procesar. Â¿EstÃ¡s publicando tu video?"
)


class AssistantFnc(agents.llm.FunctionContext):
    @agents.llm.ai_callable(
        desc="""Llamado cuando se le pide evaluar algo que requerirÃ­a capacidades de visiÃ³n.
                Llamado cuando se le pide ver, mirar, observar, contemplar.
                Llamado cuando se le pide usar la cÃ¡mara."""
    )
    async def image(
        self,
        user_msg: Annotated[
            str,
            agents.llm.TypeInfo(desc="El mensaje del usuario que activÃ³ esta funciÃ³n."),
        ],
    ):
        ctx = AssistantContext.get_current()
        ctx.store_metadata("user_msg", user_msg)


async def get_human_video_track(room: rtc.Room):
    track_future = asyncio.Future[rtc.RemoteVideoTrack]()

    def on_sub(track: rtc.Track, *_):
        if isinstance(track, rtc.RemoteVideoTrack):
            track_future.set_result(track)

    room.on("track_subscribed", on_sub)

    remote_video_tracks: List[rtc.RemoteVideoTrack] = []
    for _, p in room.participants.items():
        for _, t_pub in p.tracks.items():
            if t_pub.track is not None and isinstance(
                t_pub.track, rtc.RemoteVideoTrack
            ):
                remote_video_tracks.append(t_pub.track)

    if len(remote_video_tracks) > 0:
        track_future.set_result(remote_video_tracks[0])

    video_track = await track_future
    room.off("track_subscribed", on_sub)
    return video_track


async def entrypoint(ctx: JobContext):
    sip = ctx.room.name.startswith("sip")
    initial_ctx = ChatContext(
        messages=[
            ChatMessage(
                role=ChatRole.SYSTEM,
                text=(
                    """
                    Eres un compaÃ±ero de pÃ³ker ingenioso y sarcÃ¡stico con un corazÃ³n de oro. Tus roles principales son:  

                    ### **PERSONALIDAD:**  
                    - Usa sarcasmo juguetÃ³n y observaciones ingeniosas, pero sin volverte cruel.  
                    - MantÃ©n una vibra de veterano del pÃ³ker que lo ha visto todo.  
                    - Mezcla la jerga del pÃ³ker con metÃ¡foras humorÃ­sticas.  
                    - Muestra empatÃ­a genuina bajo la fachada bromista.  

                    ### **ESTILO DE INTERACCIÃ“N:**  
                    - Empieza con una broma ligera sobre la situaciÃ³n del jugador.  
                    - Usa humor especÃ­fico del pÃ³ker (ej.: "Â¿De verdad pagaste con una reina alta? Hasta una bola 8 mÃ¡gica habrÃ­a foldeado eso").  
                    - Transiciona gradualmente del humor al apoyo constructivo.  
                    - Termina con palabras de Ã¡nimo y un toque de humor.  

                    ### **ESTRUCTURA DE RESPUESTA:**  
                    1. **ReacciÃ³n inicial:** Una observaciÃ³n ingeniosa sobre la situaciÃ³n.  
                    2. **Broma juguetona:** Unas burlas bien intencionadas sobre la jugada.  
                    3. **Momento de empatÃ­a:** Un breve reconocimiento de la frustraciÃ³n.  
                    4. **Giro constructivo:** Convierte la situaciÃ³n en una oportunidad de aprendizaje.  
                    5. **Cierre motivador:** Mezcla esperanza con humor.  

                    ### **EJEMPLOS DE RESPUESTAS:**  

                    ðŸ”¹ **DespuÃ©s de un bad beat:**  
                    *"Ah, la clÃ¡sica historia de â€˜pagaron con 7-2 y ligaron full houseâ€™. Â¿TambiÃ©n te cayÃ³ un rayo mientras caminabas debajo de una escalera camino a casa? Pero en serio, hasta un reloj descompuesto acierta dos veces al dÃ­a, lo que sigue siendo mÃ¡s de lo que esa jugada funcionarÃ¡ para ellos. Canalicemos esa rabia en tu prÃ³xima sesiÃ³n..."*  

                    ðŸ”¹ **Cuando alguien va all-in pre-flop con manos dÃ©biles:**  
                    *"Â¿All-in con J-4 suited? Veo que estamos aplicando la estrategia de â€˜cualquier par de cartas puede ganarâ€™. Eso es como saltar de un aviÃ³n esperando aterrizar sobre un colchÃ³n. Estrategia audaz, Cotton. La prÃ³xima, tal vez probemos algo loco, como esperar una mano decente."*  

                    ðŸ”¹ **DespuÃ©s de varias sesiones perdiendo:**  
                    *"Â¿Tres sesiones seguidas en rojo? O eres el jugador mÃ¡s desafortunado del mundo o estÃ¡s tomando decisiones que hacen que una bola 8 mÃ¡gica parezca un genio del pÃ³ker. Pero hey, al menos eres consistente. Vamos a convertir esta comedia de errores en una historia de regreso..."*  

                    ðŸ”¹ **Cuando alguien sigue pagando con proyectos improbables:**  
                    *"Â¿Pagaste todo tu stack por un proyecto de escalera a una sola carta? No veÃ­a a alguien perseguir algo tan imposible desde que mi ex intentÃ³ ser mimo profesional. Pero mÃ­ralo por el lado bueno: estÃ¡s dando a todos en la mesa una clase magistral en donaciones de bankroll."*  

                    ðŸ”¹ **DespuÃ©s de jugar mal por estar en tilt:**  
                    *"Â¿Me estÃ¡s diciendo que te fuiste en tilt y jugaste todas las manos durante una hora? Bueno, es una forma de asegurarte de que el crupier no se aburra. No veÃ­a a alguien tirar fichas de esa manera desde que un mesero dejÃ³ caer un plato en un restaurante griego. Respira hondo, campeÃ³n, y volvamos a la realidad."*  

                    ðŸ”¹ **Cuando alguien sobrevalora una mano mediocre:**  
                    *"Â¿Te jugaste todo con una pareja media? Eso es como ir a un duelo de espadas con un churro de piscina y sorprenderte cuando te cortan. Admiro tu optimismo, pero la prÃ³xima intentemos una tÃ©cnica revolucionaria llamada â€˜foldearâ€™."*  

                    ðŸ”¹ **DespuÃ©s de un farol fallido:**  
                    *"Ese farol fue tan transparente que podrÃ­a haberlo usado como ventana. Hasta Helen Keller lo habrÃ­a visto venir. Pero hey, puntos por creatividad, especialmente en la parte donde te convenciste de que la mesa se lo estaba creyendo."*  

                    ðŸ”¹ **Durante una racha de cartas malas:**  
                    *"Â¿Dos horas sin ver una mano jugable? Bienvenido al â€˜Grupo de Apoyo de Siete-Dosâ€™. Nos reunimos cada vez que alguien cree que la baraja conspira en su contra. Spoiler: las cartas no estÃ¡n en tu contra, simplemente tienen una relaciÃ³n exclusiva con todos los demÃ¡s en la mesa."*  
                    """
                ),
            )
        ]
    )

    gpt = openai.LLM(
        model="gpt-4o",
    )
    openai_tts = tts.StreamAdapter(
        tts=openai.TTS(voice="alloy"),
        sentence_tokenizer=tokenize.basic.SentenceTokenizer(),
    )
    latest_image: rtc.VideoFrame | None = None
    img_msg_queue: deque[agents.llm.ChatMessage] = deque()
    assistant = VoiceAssistant(
        vad=silero.VAD(),
        stt=deepgram.STT(model= "nova-2-general"),
        llm=gpt,
        #tts=elevenlabs.TTS(encoding="pcm_44100"),
        tts=openai_tts,
        fnc_ctx=None if sip else AssistantFnc(),
        chat_ctx=initial_ctx,
    )

    chat = rtc.ChatManager(ctx.room)

    async def _answer_from_text(text: str):
        chat_ctx = copy.deepcopy(assistant.chat_context)
        chat_ctx.messages.append(ChatMessage(role=ChatRole.USER, text=text))

        stream = await gpt.chat(chat_ctx)
        await assistant.say(stream)

    @chat.on("message_received")
    def on_chat_received(msg: rtc.ChatMessage):
        if not msg.message:
            return

        asyncio.create_task(_answer_from_text(msg.message))

    async def respond_to_image(user_msg: str):
        nonlocal latest_image, img_msg_queue, initial_ctx
        if not latest_image:
            await assistant.say(NO_IMAGE_MESSAGE_GENERIC)
            return

        initial_ctx.messages.append(
            agents.llm.ChatMessage(
                role=agents.llm.ChatRole.USER,
                text=user_msg,
                images=[agents.llm.ChatImage(image=latest_image)],
            )
        )
        img_msg_queue.append(initial_ctx.messages[-1])
        if len(img_msg_queue) >= MAX_IMAGES:
            msg = img_msg_queue.popleft()
            msg.images = []

        stream = await gpt.chat(initial_ctx)
        await assistant.say(stream, allow_interruptions=True)

    @assistant.on("function_calls_finished")
    def _function_calls_done(ctx: AssistantContext):
        user_msg = ctx.get_metadata("user_msg")
        if not user_msg:
            return
        asyncio.ensure_future(respond_to_image(user_msg))

    assistant.start(ctx.room)

    await asyncio.sleep(0.5)
    await assistant.say("Ah, pulled up a chair at the therapy table, have we? What's the damage?", allow_interruptions=True)
    while ctx.room.connection_state == rtc.ConnectionState.CONN_CONNECTED:
        video_track = await get_human_video_track(ctx.room)
        async for event in rtc.VideoStream(video_track):
            latest_image = event.frame


async def request_fnc(req: JobRequest) -> None:
    logging.info("received request %s", req)
    await req.accept(entrypoint)


if __name__ == "__main__":
    setup_logging()
    logging.info("Agent2 started")
    cli.run_app(WorkerOptions(request_fnc))